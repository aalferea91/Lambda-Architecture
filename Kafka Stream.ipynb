{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 4: Stream Kafka\n",
    "\n",
    "Once our Kafka server is up and running we can start configuring it for our project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kafka-python in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the producer and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=['ec2-3-95-18-154.compute-1.amazonaws.com:9092'], #here input the correct DNS of our kafka server\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.kafka.KafkaProducer at 0x1979dbcec40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "    'test',\n",
    "     bootstrap_servers=['ec2-3-95-18-154.compute-1.amazonaws.com:9092'], #here input the correct DNS of our kafka server\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is a loop that will keep executing, so in order to test the stream we can send messages through a producer in a different notebook\n",
    "for message in consumer:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect Kafka with our database through Kafka Connect (we could also use another service like Nifi instead of Kafka Connect).\n",
    "\n",
    "First download the plugin for Kafka connect in our EC2 machine\n",
    "\n",
    "\n",
    "```bash\n",
    "wget https://repo1.maven.org/maven2/org/mongodb/kafka/mongo-kafka-connect/1.7.0/mongo-kafka-connect-1.7.0-all.jar\n",
    "\n",
    "mv mongo-kafka-connect-1.7.0-all.jar ~/kafka/libs/\n",
    "```\n",
    "Then create a file called  `kafka/config/MongoSourceConnector.properties` using a file editor like nano.\n",
    "\n",
    "```nano kafka/config/MongoSourceConnector.properties```\n",
    "\n",
    "The file must contain the following elements (it's very important to change the parameter `connection.uri` for the connection string of our mongodb database\n",
    "\n",
    "\n",
    "```ini\n",
    "name=mongo-source\n",
    "connector.class=com.mongodb.kafka.connect.MongoSourceConnector\n",
    "tasks.max=1\n",
    "\n",
    "# Connection and source configuration\n",
    "connection.uri=mongodb+srv://aalferea91:HVPk1tchDKf71SY9@lambdaprojectcluster.epdco1f.mongodb.net/?retryWrites=true&w=majority\n",
    "database=social\n",
    "collection=likes\n",
    "\n",
    "topic.prefix=\n",
    "topic.suffix=\n",
    "poll.max.batch.size=1000\n",
    "poll.await.time.ms=5000\n",
    "\n",
    "# Change stream options\n",
    "pipeline=[]\n",
    "batch.size=0\n",
    "change.stream.full.document=updateLookup\n",
    "collation=\n",
    "```\n",
    "\n",
    "Now everything is ready to launch the connector\n",
    "\n",
    "```bash\n",
    "~/kafka/bin/connect-standalone.sh -daemon ~/kafka/config/connect-standalone.properties ~/kafka/config/MongoSourceConnector.properties\n",
    "```\n",
    "\n",
    "Now Kafka will generate new records in the topic everytime there are changes in our likes collection in mongodb.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
